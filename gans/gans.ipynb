{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quantum Randomness Meets AI: Building a Quantum-Enhanced GAN**\n",
    "\n",
    "*Unlock the power of Quantum Random Number Generators (QRNGs) to enhance your Generative Adversarial Networks (GANs) and take synthetic data generation to the next level.*\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "As artificial intelligence (AI) continues to evolve, the integration of quantum computing concepts offers exciting possibilities. One such integration is the use of **Quantum Random Number Generators (QRNGs)** in AI models. QRNGs leverage the inherent unpredictability of quantum mechanics to produce truly random numbers, unlike classical pseudo-random number generators (PRNGs), which are deterministic and potentially predictable.\n",
    "\n",
    "In this tutorial, we'll explore how to incorporate QRNGs into a Generative Adversarial Network (GAN) to generate synthetic images resembling the MNIST handwritten digits. We'll cover:\n",
    "\n",
    "- Setting up the QRNG with a caching mechanism.\n",
    "- Building a Quantum Noise Generator using QRNG.\n",
    "- Implementing a GAN that uses quantum noise in the generation process.\n",
    "- Training the Quantum GAN and visualizing the results.\n",
    "\n",
    "By the end, you'll have a working Quantum GAN that leverages quantum randomness to potentially enhance the diversity and unpredictability of the generated data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Quantum Randomness in GANs?**\n",
    "\n",
    "### **Limitations of Pseudo-Randomness**\n",
    "\n",
    "- **Predictability**: PRNGs are algorithmically generated and can be predicted if the initial seed is known.\n",
    "- **Limited Entropy**: PRNGs may not provide sufficient randomness for certain applications requiring high entropy.\n",
    "\n",
    "### **Advantages of Quantum Randomness**\n",
    "\n",
    "- **True Randomness**: QRNGs produce numbers based on quantum phenomena, ensuring unpredictability.\n",
    "- **Enhanced Diversity**: Incorporating quantum randomness may introduce more variation in generated data.\n",
    "- **Security Benefits**: True randomness can improve the robustness of models against certain types of attacks.\n",
    "\n",
    "---\n",
    "\n",
    "## **Overview**\n",
    "Below is the flowchart representing the approach:\n",
    "<img src=\"tutorial4-flowchart.png\" alt=\"Flowchart\" width=auto />\n",
    "\n",
    "---\n",
    "## **Prerequisites**\n",
    "\n",
    "- **Python 3.6+**\n",
    "- **PyTorch**\n",
    "- **NumPy**\n",
    "- **Requests library**\n",
    "- **Torchvision**\n",
    "- **An API token for your Quantum eMotion's Entropy-as-a-Service (EaaS) API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import base64\n",
    "from datetime import datetime, timedelta\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1. Setting Up the Quantum Random Number Generator**\n",
    "\n",
    "We'll create a `QuantumRandomGenerator` class to interact with the QRNG API. This class includes a caching mechanism to minimize API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumRandomGenerator:\n",
    "    def __init__(self, api_token: str, cache_ttl_minutes: int = 30):  # Fixed __init__ method\n",
    "        self.api_token = api_token\n",
    "        self.base_url = 'https://your-qrng-api-endpoint/entropy'\n",
    "        self.headers = {'Authorization': f'Bearer {self.api_token}'}\n",
    "        self.cache_ttl = timedelta(minutes=cache_ttl_minutes)\n",
    "        self._initialize_cache()\n",
    "\n",
    "    def _initialize_cache(self):\n",
    "        @lru_cache(maxsize=32)\n",
    "        def cached_quantum_fetch(num_bytes: int, timestamp: str) -> np.ndarray:\n",
    "            response = requests.get(\n",
    "                self.base_url,\n",
    "                headers=self.headers,\n",
    "                params={'size': num_bytes},\n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            qrng_base64 = data['random_number']\n",
    "            qrng_bytes = base64.b64decode(qrng_base64)\n",
    "            return np.frombuffer(qrng_bytes, dtype=np.uint8)\n",
    "        self._cached_fetch = cached_quantum_fetch\n",
    "\n",
    "    def _get_cache_key_timestamp(self) -> str:\n",
    "        now = datetime.now()\n",
    "        ttl_seconds = self.cache_ttl.total_seconds()\n",
    "        epoch_seconds = now.timestamp()\n",
    "        current_period = int(epoch_seconds // ttl_seconds)\n",
    "        period_start = datetime.fromtimestamp(current_period * ttl_seconds)\n",
    "        return period_start.isoformat()\n",
    "\n",
    "    def get_quantum_random(self, num_bytes: int) -> np.ndarray:\n",
    "        if num_bytes > 512:\n",
    "            raise ValueError(\"num_bytes cannot exceed 512\")\n",
    "        cache_timestamp = self._get_cache_key_timestamp()\n",
    "        result = self._cached_fetch(num_bytes, cache_timestamp)\n",
    "        if result is not None:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Failed to fetch quantum random numbers\")\n",
    "\n",
    "    def clear_cache(self):\n",
    "        self._cached_fetch.cache_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**\n",
    "\n",
    "- **API Endpoint**: Replace `'https://your-qrng-api-endpoint/entropy'` with your actual QRNG API endpoint.\n",
    "- **API Token**: Ensure you have a valid API token and set it appropriately.\n",
    "- **Caching Mechanism**: Uses an LRU cache to minimize API calls and handle rate limits.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Managing Quantum Random Numbers Efficiently**\n",
    "\n",
    "We'll implement a buffer system with the `QuantumRandomBuffer` class to handle large requests and minimize API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumRandomBuffer:\n",
    "    VALID_SIZES = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "    def __init__(self, qrng: QuantumRandomGenerator):  # Fixed __init__ method\n",
    "        self.qrng = qrng\n",
    "        self.buffer = np.array([], dtype=np.uint8)\n",
    "\n",
    "    def _get_optimal_chunk_size(self, required_size: int) -> int:\n",
    "        for size in self.VALID_SIZES:\n",
    "            if size >= required_size:\n",
    "                return size\n",
    "        return self.VALID_SIZES[-1]\n",
    "\n",
    "    def get_numbers(self, size: int) -> np.ndarray:\n",
    "        while len(self.buffer) < size:\n",
    "            remaining = size - len(self.buffer)\n",
    "            chunk_size = self._get_optimal_chunk_size(min(512, remaining))\n",
    "            new_numbers = self.qrng.get_quantum_random(chunk_size)\n",
    "            self.buffer = np.concatenate([self.buffer, new_numbers])\n",
    "        result = self.buffer[:size]\n",
    "        self.buffer = self.buffer[size:]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features:**\n",
    "\n",
    "- **Buffering**: Stores quantum random numbers to reduce API requests.\n",
    "- **Optimal Chunk Size**: Ensures requests are made in sizes supported by the API.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Implementing Quantum Noise for the GAN**\n",
    "\n",
    "We'll create a `QuantumNoiseGenerator` class that uses the `QuantumRandomBuffer` to generate noise for the GAN's latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumNoiseGenerator:\n",
    "    def __init__(self, qrng_buffer: QuantumRandomBuffer):\n",
    "        self.qrng_buffer = qrng_buffer\n",
    "        \n",
    "    def generate_noise(self, batch_size: int, latent_dim: int) -> torch.Tensor:\n",
    "        # Get quantum random numbers and convert to normal distribution\n",
    "        size = batch_size * latent_dim\n",
    "        quantum_bytes = self.qrng_buffer.get_numbers(size)\n",
    "        \n",
    "        # Convert to uniform [0, 1]\n",
    "        uniform = quantum_bytes.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to normal distribution using Box-Muller transform\n",
    "        shape = (batch_size, latent_dim)\n",
    "        if size % 2 != 0:\n",
    "            uniform = np.append(uniform, self.qrng_buffer.get_numbers(1)[0] / 255.0)\n",
    "            \n",
    "        uniform_reshape = uniform.reshape(-1, 2)\n",
    "        \n",
    "        r = np.sqrt(-2.0 * np.log(uniform_reshape[:, 0]))\n",
    "        theta = 2.0 * np.pi * uniform_reshape[:, 1]\n",
    "        \n",
    "        normal = np.column_stack([r * np.cos(theta), r * np.sin(theta)])\n",
    "        normal = normal.reshape(shape)[:batch_size, :latent_dim]\n",
    "        \n",
    "        return torch.from_numpy(normal).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Uniform to Normal**: Uses the Box-Muller transform to convert uniformly distributed quantum random numbers into normally distributed noise suitable for the GAN's latent space.\n",
    "- **Batch Processing**: Generates noise in batches to match the input requirements of the GAN.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Building the Quantum GAN**\n",
    "\n",
    "### **4.1 The Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        img = self.model(z)\n",
    "        return img.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 The Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        img_flat = img.view(-1, 784)\n",
    "        return self.model(img_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 The Quantum GAN Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumGAN:\n",
    "    def __init__(self, \n",
    "                 latent_dim: int,\n",
    "                 qrng_buffer: QuantumRandomBuffer,\n",
    "                 device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "        self.quantum_noise = QuantumNoiseGenerator(qrng_buffer)\n",
    "        \n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.discriminator = Discriminator().to(device)\n",
    "        \n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "    def train_step(self, real_images: torch.Tensor) -> Tuple[float, float]:\n",
    "        batch_size = real_images.size(0)\n",
    "        real_label = torch.ones(batch_size, 1).to(self.device)\n",
    "        fake_label = torch.zeros(batch_size, 1).to(self.device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        real_output = self.discriminator(real_images)\n",
    "        d_loss_real = self.criterion(real_output, real_label)\n",
    "        \n",
    "        z = self.quantum_noise.generate_noise(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(z)\n",
    "        fake_output = self.discriminator(fake_images.detach())\n",
    "        d_loss_fake = self.criterion(fake_output, fake_label)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        z = self.quantum_noise.generate_noise(batch_size, self.latent_dim).to(self.device)\n",
    "        fake_images = self.generator(z)\n",
    "        fake_output = self.discriminator(fake_images)\n",
    "        \n",
    "        g_loss = self.criterion(fake_output, real_label)\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        return d_loss.item(), g_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components:**\n",
    "\n",
    "- **Quantum Noise in Latent Space**: Uses quantum-generated noise for the generator's input.\n",
    "- **GAN Training Loop**: Standard GAN training steps adapted to include quantum noise.\n",
    "- **Loss Functions**: Uses Binary Cross-Entropy Loss for both generator and discriminator.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Training the Quantum GAN**\n",
    "\n",
    "### **5.1 Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_quantum_gan(qrng_token: str, \n",
    "                     num_epochs: int = 100,\n",
    "                     batch_size: int = 64,\n",
    "                     latent_dim: int = 100,\n",
    "                     save_dir: str = \"generated_images\"):\n",
    "    # Create save directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    # Initialize QRNG\n",
    "    qrng = QuantumRandomGenerator(api_token=qrng_token)\n",
    "    qrng_buffer = QuantumRandomBuffer(qrng)\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    mnist = torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize Quantum GAN\n",
    "    qgan = QuantumGAN(latent_dim=latent_dim, qrng_buffer=qrng_buffer, device=device)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            d_loss, g_loss = qgan.train_step(real_images)\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "                      f\"Batch [{batch_idx}/{len(dataloader)}] \"\n",
    "                      f\"D_loss: {d_loss:.4f} \"\n",
    "                      f\"G_loss: {g_loss:.4f}\")\n",
    "                \n",
    "                # Save generated images\n",
    "                with torch.no_grad():\n",
    "                    z = qgan.quantum_noise.generate_noise(16, latent_dim).to(device)\n",
    "                    fake_images = qgan.generator(z)\n",
    "                    torchvision.utils.save_image(\n",
    "                        fake_images,\n",
    "                        os.path.join(save_dir, f'fake_images_epoch_{epoch}_batch_{batch_idx}.png'),\n",
    "                        normalize=True,\n",
    "                        nrow=4\n",
    "                    )\n",
    "    \n",
    "    return qgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Details:**\n",
    "\n",
    "- **Dataset**: Uses the MNIST dataset of handwritten digits.\n",
    "- **Checkpointing**: Saves generated images every 100 batches for visualization.\n",
    "- **Epochs and Batch Size**: Configurable parameters to control training duration.\n",
    "\n",
    "### **5.2 Running the Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get API token from environment variable\n",
    "qrng_token = os.getenv('API_TOKEN')\n",
    "if qrng_token is None:\n",
    "    raise ValueError(\"Please set the API_TOKEN environment variable\")\n",
    "\n",
    "# Train the model\n",
    "model = train_quantum_gan(qrng_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**\n",
    "\n",
    "- **API Token**: Ensure your QRNG API token is set in the environment variable `API_TOKEN`.\n",
    "- **Generated Images**: Check the `generated_images` directory to see the outputs of the generator during training.\n",
    "\n",
    "\n",
    "# Quantum GAN Results Across Epochs\n",
    "\n",
    "Below, you can see the progression of images generated by the Quantum GAN model across four different epochs. Observe how the clarity and quality improve over time.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>Epoch 1</strong></td>\n",
    "    <td><strong>Epoch 3</strong></td>\n",
    "    <td><strong>Epoch 22</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"./images/fake_images_epoch_0_batch_500.png\" width=\"300\" height=\"300\" alt=\"Epoch 1\"></td>\n",
    "    <td><img src=\"./images/fake_images_epoch_3_batch_300.png\" width=\"300\" height=\"300\" alt=\"Epoch 3\"></td>\n",
    "    <td><img src=\"./images/fake_images_epoch_22_batch_100.png\" width=\"300\" height=\"300\" alt=\"Epoch 22\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>Epoch 32</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"./images/fake_images_epoch_32_batch_300.png\" width=\"300\" height=\"300\" alt=\"Epoch 32\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n",
    "### Progression Details\n",
    "\n",
    "- **Epoch 1**: Initial results are noisy and pixelated, with some round and circular shapes starting to form.\n",
    "- **Epoch 3**: Outputs gain more clarity, beginning to form the structure of two distinct digits.\n",
    "- **Epoch 22**: Clarity is significantly enhanced, with outputs showing much more refined shapes.\n",
    "- **Epoch 32**: Achieves the best quality overall, with well-defined results and minimal noise.\n",
    "\n",
    "## **7. Conclusion**\n",
    "\n",
    "In this tutorial, we've successfully integrated quantum randomness into a GAN for image generation. By using a QRNG, we've introduced true randomness into the model's latent space, potentially enhancing the diversity and unpredictability of the generated images.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **Quantum Randomness**: Provides a source of true randomness, which may improve model robustness.\n",
    "- **GAN Architecture**: Remains standard, allowing easy integration of quantum noise.\n",
    "- **Potential Benefits**: Opens avenues for research into the effects of quantum randomness on generative models.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- **Experimentation**: Try training the Quantum GAN on different datasets.\n",
    "- **Hyperparameter Tuning**: Adjust the latent dimension, learning rates, and network architectures.\n",
    "- **Comparative Analysis**: Compare the performance of the Quantum GAN with a traditional GAN using PRNGs.\n",
    "\n",
    "---\n",
    "\n",
    "## **References**\n",
    "\n",
    "- **Quantum Random Number Generators**: [Wikipedia](https://en.wikipedia.org/wiki/Quantum_random_number_generator)\n",
    "- **Generative Adversarial Networks**: [Ian Goodfellow's Paper](https://arxiv.org/abs/1406.2661)\n",
    "- **PyTorch Documentation**: [PyTorch Official Site](https://pytorch.org/docs/stable/index.html)\n",
    "- **MNIST Dataset**: [Yann LeCun's Website](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "---\n",
    "\n",
    "*Embrace the future of AI by integrating quantum technologies into your models today! If you found this tutorial helpful, please share it with others interested in the exciting intersection of quantum computing and artificial intelligence.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
